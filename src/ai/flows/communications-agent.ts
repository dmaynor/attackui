
'use server';
/**
 * @fileOverview A Communications AI agent that generates news scripts and conceptually initiates video creation.
 *
 * - handleCommunicationsTask - A function that handles script generation and mock video creation.
 * - CommunicationsTaskInput - The input type for the handleCommunicationsTask function.
 * - CommunicationsTaskOutput - The return type for the handleCommunicationsTask function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

// Schema for the conceptual Synthesia video creation tool's input
const SynthesiaToolInputSchema = z.object({
  script: z.string().describe("The script for the video."),
  avatarId: z.string().optional().describe("The ID of the Synthesia avatar to use (e.g., 'anna_costume1_cameraA'). Default to a generic newscaster if not provided."),
  title: z.string().optional().describe("The title for the video. If not provided, a generic title will be used."),
  testMode: z.boolean().optional().describe("Whether to run Synthesia in test mode. Defaults to true for this conceptual tool."),
});

// Schema for the conceptual Synthesia video creation tool's output
const SynthesiaToolOutputSchema = z.object({
  status: z.string().describe("Status of the video creation request (e.g., 'Video creation initiated', 'Error')."),
  videoId: z.string().optional().describe("A mock ID of the video if successfully initiated."),
  details: z.string().optional().describe("Additional details or mock error messages."),
});

// Define the conceptual Synthesia video creation tool
const synthesiaVideoCreationTool = ai.defineTool(
  {
    name: 'synthesiaVideoCreationTool',
    description: 'Initiates video creation using a script, avatar, and title. This is a conceptual tool that mocks interaction with a video generation service like Synthesia.',
    inputSchema: SynthesiaToolInputSchema,
    outputSchema: SynthesiaToolOutputSchema,
  },
  async (input) => {
    // This is a placeholder. In a real implementation, this would call the Synthesia API.
    console.log(`[SynthesiaTool] Called with script (first 50 chars): ${input.script.substring(0,50)}...`);
    console.log(`[SynthesiaTool] Avatar ID: ${input.avatarId}, Title: ${input.title}, TestMode: ${input.testMode ?? true}`);
    
    // Simulate a successful API call
    const mockVideoId = `syn_${Date.now()}`;
    return {
      status: 'Video creation successfully initiated (mocked).',
      videoId: mockVideoId,
      details: `Conceptual video for title "${input.title || 'Untitled Update'}" with avatar "${input.avatarId || 'default_newscaster'}" is being "generated".`,
    };
  }
);

// Schema for the Communications Agent's input
const CommunicationsAgentInputSchema = z.object({
  topic: z.string().describe("The main topic for the news update script."),
  avatarId: z.string().optional().describe("Optional Synthesia avatar ID to suggest for the video."),
  title: z.string().optional().describe("Optional title for the video update."),
});
export type CommunicationsTaskInput = z.infer<typeof CommunicationsAgentInputSchema>;

// Schema for the Communications Agent's output
const CommunicationsAgentOutputSchema = z.object({
  generatedScript: z.string().describe("The news script generated by the agent."),
  videoCreationStatus: z.string().describe("The status message from attempting to create the video."),
  videoId: z.string().optional().describe("The ID of the video if generation was initiated (mocked)."),
  toolResponseDetails: z.string().optional().describe("Further details from the video creation tool."),
});
export type CommunicationsTaskOutput = z.infer<typeof CommunicationsAgentOutputSchema>;


export async function handleCommunicationsTask(input: CommunicationsTaskInput): Promise<CommunicationsTaskOutput> {
  return communicationsAgentFlow(input);
}

const communicationsAgentPrompt = ai.definePrompt({
  name: 'communicationsAgentPrompt',
  input: {schema: CommunicationsAgentInputSchema},
  output: {schema: CommunicationsAgentOutputSchema},
  tools: [synthesiaVideoCreationTool],
  prompt: `You are the Communications Agent for "Team Violator". Your role is to create engaging news updates.

Task:
1.  You will be given a 'topic'.
2.  Generate a concise, professional, and engaging news script (around 3-5 sentences) suitable for a video update based on this 'topic'.
3.  After generating the script, use the 'synthesiaVideoCreationTool' to "create" a video for this script.
    *   Use the 'avatarId' provided in the input if available for the tool. If not, you can suggest a generic one like 'newscaster_male_close_up'.
    *   Use the 'title' provided in the input if available for the tool. If not, create a suitable title based on the topic.
    *   Always set 'testMode' to true for the tool.
4.  Your final response should include the 'generatedScript', the 'videoCreationStatus' from the tool, any 'videoId' returned, and 'toolResponseDetails'.

Input Topic: {{{topic}}}
{{#if avatarId}}Suggested Avatar ID for video: {{{avatarId}}}{{/if}}
{{#if title}}Suggested Title for video: {{{title}}}{{/if}}
`,
});

const communicationsAgentFlow = ai.defineFlow(
  {
    name: 'communicationsAgentFlow',
    inputSchema: CommunicationsAgentInputSchema,
    outputSchema: CommunicationsAgentOutputSchema,
  },
  async (input) => {
    const {output} = await communicationsAgentPrompt(input);
    
    if (output) {
        // The LLM should have populated these fields based on the prompt instructions and tool use.
        return output; 
    }

    // Fallback if LLM output is not as expected or tool use failed in a way not caught by the prompt.
    return {
      generatedScript: "Error: Could not generate script or interact with the video tool.",
      videoCreationStatus: "Failed to process communication task.",
    };
  }
);
